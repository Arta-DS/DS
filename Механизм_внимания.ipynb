{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Arta-DS/DS/blob/main/%D0%9C%D0%B5%D1%85%D0%B0%D0%BD%D0%B8%D0%B7%D0%BC_%D0%B2%D0%BD%D0%B8%D0%BC%D0%B0%D0%BD%D0%B8%D1%8F.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "QxmiEffaQ3fV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af6884df-3f9e-40f4-d22c-22efed56ee8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-10-18 09:02:00--  http://www.manythings.org/anki/rus-eng.zip\n",
            "Resolving www.manythings.org (www.manythings.org)... 173.254.30.110\n",
            "Connecting to www.manythings.org (www.manythings.org)|173.254.30.110|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 17201311 (16M) [application/zip]\n",
            "Saving to: ‘rus-eng.zip’\n",
            "\n",
            "rus-eng.zip         100%[===================>]  16.40M  6.34MB/s    in 2.6s    \n",
            "\n",
            "2025-10-18 09:02:03 (6.34 MB/s) - ‘rus-eng.zip’ saved [17201311/17201311]\n",
            "\n",
            "Archive:  rus-eng.zip\n",
            "  inflating: rus.txt                 \n",
            "  inflating: _about.txt              \n",
            "Всего пар предложений: 527642\n",
            "Пример пары: ['Go.', 'Марш!']\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import spacy\n",
        "import random\n",
        "import math\n",
        "import time\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Загрузка и распаковка данных\n",
        "!wget http://www.manythings.org/anki/rus-eng.zip\n",
        "!unzip rus-eng.zip\n",
        "\n",
        "# Чтение данных\n",
        "with open('rus.txt', 'r', encoding='utf-8') as f:\n",
        "    lines = f.read().split('\\n')\n",
        "\n",
        "# Создание пар предложений\n",
        "pairs = [[line.split('\\t')[0], line.split('\\t')[1]] for line in lines if line]\n",
        "print(f\"Всего пар предложений: {len(pairs)}\")\n",
        "print(\"Пример пары:\", pairs[0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Обрезаем датасет для ускорения обучения на CPU\n",
        "# Возьмем первые 15000 пар\n",
        "NUM_SAMPLES = 15000\n",
        "pairs = pairs[:NUM_SAMPLES]\n",
        "print(f\"Используем урезанный датасет из {len(pairs)} пар.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_i5g5QVUDkI",
        "outputId": "07d505d3-22f7-4711-edc9-1a1b0d937abc"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Используем урезанный датасет из 15000 пар.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3hCqHI2Q-zy",
        "outputId": "610d8835-506f-44b2-94aa-336e8b6dce62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Размер словаря английского языка (источник): 2307\n",
            "Размер словаря русского языка (цель): 8074\n",
            "Обучающая выборка: 12150 пар\n",
            "Валидационная выборка: 1350 пар\n",
            "Тестовая выборка: 1500 пар\n"
          ]
        }
      ],
      "source": [
        "# Установка seed для воспроизводимости\n",
        "SEED = 1234\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "# Инициализация токенизатора для английского\n",
        "spacy_en = spacy.load('en_core_web_sm')\n",
        "\n",
        "# Простая токенизация для русского языка (разделение по пробелам)\n",
        "def tokenize_ru(text):\n",
        "    return text.split()\n",
        "\n",
        "# Создание словарей\n",
        "class Vocabulary:\n",
        "    def __init__(self, tokenize_func):\n",
        "        self.tokenize = tokenize_func\n",
        "        self.word2idx = {'<pad>': 0, '<sos>': 1, '<eos>': 2, '<unk>': 3}\n",
        "        self.idx2word = {v: k for k, v in self.word2idx.items()}\n",
        "        self.word_count = {}\n",
        "\n",
        "    def build_vocab(self, sentences):\n",
        "        for sentence in sentences:\n",
        "            token_objects = self.tokenize(sentence.lower())\n",
        "            tokens = [token.text if hasattr(token, 'text') else token for token in token_objects]\n",
        "            for word in tokens:\n",
        "                self.word_count[word] = self.word_count.get(word, 0) + 1\n",
        "\n",
        "        # Включаем в словарь ВСЕ слова, даже те, что встретились 1 раз\n",
        "        for word, count in self.word_count.items():\n",
        "            if count >= 1: # Было 2\n",
        "                if word not in self.word2idx:\n",
        "                    self.word2idx[word] = len(self.word2idx)\n",
        "                    self.idx2word[len(self.idx2word)] = word\n",
        "\n",
        "    def numericalize(self, sentence):\n",
        "        token_objects = self.tokenize(sentence.lower())\n",
        "        tokens = [token.text if hasattr(token, 'text') else token for token in token_objects]\n",
        "        return [self.word2idx.get(token, self.word2idx['<unk>']) for token in tokens]\n",
        "\n",
        "# Подготовка данных\n",
        "en_sentences = [pair[0] for pair in pairs]\n",
        "ru_sentences = [pair[1] for pair in pairs]\n",
        "\n",
        "# Создание словарей\n",
        "SRC_vocab = Vocabulary(spacy_en.tokenizer)\n",
        "SRC_vocab.build_vocab(en_sentences)\n",
        "\n",
        "TRG_vocab = Vocabulary(tokenize_ru)\n",
        "TRG_vocab.build_vocab(ru_sentences)\n",
        "\n",
        "print(f\"Размер словаря английского языка (источник): {len(SRC_vocab.word2idx)}\")\n",
        "print(f\"Размер словаря русского языка (цель): {len(TRG_vocab.word2idx)}\")\n",
        "\n",
        "# Преобразование предложений в тензоры\n",
        "def process_data(pairs, src_vocab, trg_vocab):\n",
        "    src_data = []\n",
        "    trg_data = []\n",
        "    for src, trg in pairs:\n",
        "        src_indices = [src_vocab.word2idx['<sos>']] + src_vocab.numericalize(src) + [src_vocab.word2idx['<eos>']]\n",
        "        trg_indices = [trg_vocab.word2idx['<sos>']] + trg_vocab.numericalize(trg) + [trg_vocab.word2idx['<eos>']]\n",
        "        src_data.append(torch.tensor(src_indices, dtype=torch.long))\n",
        "        trg_data.append(torch.tensor(trg_indices, dtype=torch.long))\n",
        "    return src_data, trg_data\n",
        "\n",
        "src_data, trg_data = process_data(pairs, SRC_vocab, TRG_vocab)\n",
        "\n",
        "# Разделение на обучающую и тестовую выборки\n",
        "# Сначала отделяем тестовую выборку (10%)\n",
        "train_val_size = int(0.9 * len(src_data))\n",
        "test_size = len(src_data) - train_val_size\n",
        "src_train_val, src_test = torch.utils.data.random_split(src_data, [train_val_size, test_size])\n",
        "trg_train_val, trg_test = torch.utils.data.random_split(trg_data, [train_val_size, test_size])\n",
        "\n",
        "# Затем из оставшихся 90% отделяем валидационную (10% от 90% = 9% от общего)\n",
        "train_size = int(0.9 * train_val_size) # 81% от общего объема\n",
        "valid_size = train_val_size - train_size # 9% от общего объема\n",
        "src_train, src_valid = torch.utils.data.random_split(src_train_val, [train_size, valid_size])\n",
        "trg_train, trg_valid = torch.utils.data.random_split(trg_train_val, [train_size, valid_size])\n",
        "\n",
        "# Создание DataLoader'ов\n",
        "\n",
        "BATCH_SIZE = 32  # Было 128\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # Останется 'cpu'\n",
        "\n",
        "def collate_fn(batch):\n",
        "    src_batch, trg_batch = zip(*batch)\n",
        "    src_batch = pad_sequence(src_batch, padding_value=SRC_vocab.word2idx['<pad>'])\n",
        "    trg_batch = pad_sequence(trg_batch, padding_value=TRG_vocab.word2idx['<pad>'])\n",
        "    return src_batch, trg_batch\n",
        "\n",
        "train_dataset = list(zip(src_train, trg_train))\n",
        "valid_dataset = list(zip(src_valid, trg_valid))\n",
        "test_dataset = list(zip(src_test, trg_test))\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "print(f\"Обучающая выборка: {len(src_train)} пар\")\n",
        "print(f\"Валидационная выборка: {len(src_valid)} пар\")\n",
        "print(f\"Тестовая выборка: {len(src_test)} пар\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "WeQKhfkiQ_Sc"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "        self.rnn = nn.GRU(emb_dim, enc_hid_dim, bidirectional=True)\n",
        "        self.fc = nn.Linear(enc_hid_dim * 2, dec_hid_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, src):\n",
        "        # src = [src_len, batch_size]\n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "        # embedded = [src_len, batch_size, emb_dim]\n",
        "\n",
        "        outputs, hidden = self.rnn(embedded)\n",
        "        # outputs = [src_len, batch_size, hid_dim * num_directions]\n",
        "        # hidden = [n_layers * num_directions, batch_size, hid_dim]\n",
        "\n",
        "        # Инициализация состояния декодера\n",
        "        hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1)))\n",
        "        # hidden = [batch_size, dec_hid_dim]\n",
        "\n",
        "        return outputs, hidden"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "yyAacWmLRC54"
      },
      "outputs": [],
      "source": [
        "class DotProductAttention(nn.Module):\n",
        "    def __init__(self, enc_hid_dim, dec_hid_dim):\n",
        "        super().__init__()\n",
        "        self.attn = nn.Linear((enc_hid_dim * 2) + dec_hid_dim, dec_hid_dim)\n",
        "        self.v = nn.Linear(dec_hid_dim, 1, bias=False)\n",
        "\n",
        "    def forward(self, hidden, encoder_outputs, mask):\n",
        "        # hidden = [batch_size, dec_hid_dim]\n",
        "        # encoder_outputs = [src_len, batch_size, enc_hid_dim * 2]\n",
        "        # mask = [batch_size, src_len]\n",
        "\n",
        "        batch_size = encoder_outputs.shape[1]\n",
        "        src_len = encoder_outputs.shape[0]\n",
        "\n",
        "        # Повторяем скрытое состояние декодера для каждого слова в источнике\n",
        "        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
        "        # hidden = [batch_size, src_len, dec_hid_dim]\n",
        "\n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "        # encoder_outputs = [batch_size, src_len, enc_hid_dim * 2]\n",
        "\n",
        "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim=2)))\n",
        "        # energy = [batch_size, src_len, dec_hid_dim]\n",
        "\n",
        "        attention = self.v(energy).squeeze(2)\n",
        "        # attention = [batch_size, src_len]\n",
        "\n",
        "        attention = attention.masked_fill(mask == 0, -1e10)\n",
        "\n",
        "        return torch.softmax(attention, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "PHyajpgTRFm3"
      },
      "outputs": [],
      "source": [
        "class MLPAttention(nn.Module):\n",
        "    def __init__(self, enc_hid_dim, dec_hid_dim):\n",
        "        super().__init__()\n",
        "        self.attn = nn.Linear(enc_hid_dim * 2 + dec_hid_dim, dec_hid_dim)\n",
        "        self.v = nn.Linear(dec_hid_dim, 1, bias = False)\n",
        "\n",
        "    def forward(self, hidden, encoder_outputs, mask):\n",
        "        # hidden = [batch_size, dec_hid_dim]\n",
        "        # encoder_outputs = [src_len, batch_size, enc_hid_dim * 2]\n",
        "        # mask = [batch_size, src_len]\n",
        "\n",
        "        batch_size = encoder_outputs.shape[1]\n",
        "        src_len = encoder_outputs.shape[0]\n",
        "\n",
        "        # Повторяем скрытое состояние декодера для каждого слова в источнике\n",
        "        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
        "        # hidden = [batch_size, src_len, dec_hid_dim]\n",
        "\n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "        # encoder_outputs = [batch_size, src_len, enc_hid_dim * 2]\n",
        "\n",
        "        # Конкатенируем скрытые состояния энкодера и декодера\n",
        "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim=2)))\n",
        "        # energy = [batch_size, src_len, dec_hid_dim]\n",
        "\n",
        "        attention = self.v(energy).squeeze(2)\n",
        "        # attention = [batch_size, src_len]\n",
        "\n",
        "        # Применяем маску, чтобы модель не обращала внимание на <pad> токены\n",
        "        attention = attention.masked_fill(mask == 0, -1e10)\n",
        "\n",
        "        return torch.softmax(attention, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "h-QE_jQvRK7r"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout, attention):\n",
        "        super().__init__()\n",
        "        self.output_dim = output_dim\n",
        "        self.attention = attention\n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "        self.rnn = nn.GRU((enc_hid_dim * 2) + emb_dim, dec_hid_dim)\n",
        "        self.fc_out = nn.Linear((enc_hid_dim * 2) + dec_hid_dim + emb_dim, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs, mask):\n",
        "        # input = [batch_size]\n",
        "        # hidden = [batch_size, dec_hid_dim]\n",
        "        # encoder_outputs = [src_len, batch_size, enc_hid_dim * 2]\n",
        "        # mask = [batch_size, src_len]\n",
        "\n",
        "        input = input.unsqueeze(0)\n",
        "        # input = [1, batch_size]\n",
        "\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        # embedded = [1, batch_size, emb_dim]\n",
        "\n",
        "        # Вычисление весов внимания\n",
        "        a = self.attention(hidden, encoder_outputs, mask)\n",
        "        # a = [batch_size, src_len]\n",
        "\n",
        "        a = a.unsqueeze(1)\n",
        "        # a = [batch_size, 1, src_len]\n",
        "\n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "        # encoder_outputs = [batch_size, src_len, enc_hid_dim * 2]\n",
        "\n",
        "        weighted = torch.bmm(a, encoder_outputs)\n",
        "        # weighted = [batch_size, 1, enc_hid_dim * 2]\n",
        "\n",
        "        weighted = weighted.permute(1, 0, 2)\n",
        "        # weighted = [1, batch_size, enc_hid_dim * 2]\n",
        "\n",
        "        rnn_input = torch.cat((embedded, weighted), dim = 2)\n",
        "        # rnn_input = [1, batch_size, (enc_hid_dim * 2) + emb_dim]\n",
        "\n",
        "        output, hidden = self.rnn(rnn_input, hidden.unsqueeze(0))\n",
        "        # output = [seq_len, batch_size, dec_hid_dim]\n",
        "        # hidden = [n_layers, batch_size, dec_hid_dim]\n",
        "\n",
        "        assert (output == hidden).all()\n",
        "\n",
        "        embedded = embedded.squeeze(0)\n",
        "        output = output.squeeze(0)\n",
        "        weighted = weighted.squeeze(0)\n",
        "\n",
        "        prediction = self.fc_out(torch.cat((output, weighted, embedded), dim = 1))\n",
        "        # prediction = [batch_size, output_dim]\n",
        "\n",
        "        return prediction, hidden.squeeze(0), a.squeeze(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "5hdMrCPORN4k"
      },
      "outputs": [],
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, src_pad_idx, device):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.src_pad_idx = src_pad_idx\n",
        "        self.device = device\n",
        "\n",
        "    def create_mask(self, src):\n",
        "        mask = (src != self.src_pad_idx).permute(1, 0)\n",
        "        return mask\n",
        "\n",
        "    def forward(self, src, trg, teacher_forcing_ratio = 0.5):\n",
        "        # src = [src_len, batch_size]\n",
        "        # trg = [trg_len, batch_size]\n",
        "\n",
        "        batch_size = src.shape[1]\n",
        "        trg_len = trg.shape[0]\n",
        "        trg_vocab_size = self.decoder.output_dim\n",
        "\n",
        "        # Тензор для хранения выходов\n",
        "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
        "\n",
        "        # Скрытое состояние энкодера\n",
        "        encoder_outputs, hidden = self.encoder(src)\n",
        "        # encoder_outputs = [src_len, batch_size, enc_hid_dim * 2]\n",
        "        # hidden = [batch_size, dec_hid_dim]\n",
        "\n",
        "        # Первый вход в декодер - это <sos> токен\n",
        "        input = trg[0,:]\n",
        "\n",
        "        mask = self.create_mask(src)\n",
        "\n",
        "        for t in range(1, trg_len):\n",
        "            # Вставляем входное слово, предыдущее скрытое состояние и все выходы энкодера\n",
        "            # Получаем предсказание, новое скрытое состояние и веса внимания\n",
        "            output, hidden, _ = self.decoder(input, hidden, encoder_outputs, mask)\n",
        "            # output = [batch_size, output_dim]\n",
        "            # hidden = [batch_size, dec_hid_dim]\n",
        "\n",
        "            # Сохраняем предсказание\n",
        "            outputs[t] = output\n",
        "\n",
        "            # Решаем, использовать ли teacher forcing\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            top1 = output.argmax(1)\n",
        "            input = trg[t] if teacher_force else top1\n",
        "\n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "YrP0JXotRQzn"
      },
      "outputs": [],
      "source": [
        "INPUT_DIM = len(SRC_vocab.word2idx)\n",
        "OUTPUT_DIM = len(TRG_vocab.word2idx)\n",
        "ENC_EMB_DIM = 128  # Было 256\n",
        "DEC_EMB_DIM = 128  # Было 256\n",
        "ENC_HID_DIM = 256  # Было 512\n",
        "DEC_HID_DIM = 256  # Было 512\n",
        "ENC_DROPOUT = 0.5\n",
        "DEC_DROPOUT = 0.5\n",
        "SRC_PAD_IDX = SRC_vocab.word2idx['<pad>']\n",
        "\n",
        "#  Модель 1: Внимание на основе скалярного произведения\n",
        "attn_dot = DotProductAttention(ENC_HID_DIM, DEC_HID_DIM)\n",
        "enc_dot = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT)\n",
        "dec_dot = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT, attn_dot)\n",
        "model_dot = Seq2Seq(enc_dot, dec_dot, SRC_PAD_IDX, DEVICE).to(DEVICE)\n",
        "\n",
        "#  Модель 2: Внимание на основе MLP\n",
        "attn_mlp = MLPAttention(ENC_HID_DIM, DEC_HID_DIM)\n",
        "enc_mlp = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT)\n",
        "dec_mlp = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT, attn_mlp)\n",
        "model_mlp = Seq2Seq(enc_mlp, dec_mlp, SRC_PAD_IDX, DEVICE).to(DEVICE)\n",
        "\n",
        "\n",
        "def initialize_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "        if 'weight' in name:\n",
        "            nn.init.normal_(param.data, mean=0, std=0.01)\n",
        "        else:\n",
        "            nn.init.constant_(param.data, 0)\n",
        "\n",
        "model_dot.apply(initialize_weights)\n",
        "model_mlp.apply(initialize_weights)\n",
        "\n",
        "# Оптимизаторы и функция потерь\n",
        "optimizer_dot = optim.Adam(model_dot.parameters())\n",
        "optimizer_mlp = optim.Adam(model_mlp.parameters())\n",
        "\n",
        "TRG_PAD_IDX = TRG_vocab.word2idx['<pad>']\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=TRG_PAD_IDX)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "GCWlfCmpRWDW"
      },
      "outputs": [],
      "source": [
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    for i, (src, trg) in enumerate(iterator):\n",
        "        src, trg = src.to(DEVICE), trg.to(DEVICE)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(src, trg)\n",
        "        # output = [trg_len, batch_size, output_dim]\n",
        "        output_dim = output.shape[-1]\n",
        "\n",
        "        output = output[1:].view(-1, output_dim)\n",
        "        trg = trg[1:].view(-1)\n",
        "        # trg = [(trg_len - 1) * batch_size]\n",
        "\n",
        "        loss = criterion(output, trg)\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(iterator)\n",
        "\n",
        "def evaluate(model, iterator, criterion):\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for i, (src, trg) in enumerate(iterator):\n",
        "            src, trg = src.to(DEVICE), trg.to(DEVICE)\n",
        "\n",
        "            output = model(src, trg, 0) # turn off teacher forcing\n",
        "            # output = [trg_len, batch_size, output_dim]\n",
        "            output_dim = output.shape[-1]\n",
        "\n",
        "            output = output[1:].view(-1, output_dim)\n",
        "            trg = trg[1:].view(-1)\n",
        "            # trg = [(trg_len - 1) * batch_size]\n",
        "\n",
        "            loss = criterion(output, trg)\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(iterator)\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vb7swP0vRY4_",
        "outputId": "50ab4390-11b0-4a48-b24b-8f57136b9839"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Обучение модели с Dot-Product Attention ---\n",
            "Epoch: 01 | Time: 3m 3s\n",
            "\tTrain Loss: 5.519 | Train PPL: 249.343\n",
            "\t Val. Loss: 5.219 |  Val. PPL: 184.674\n",
            "Epoch: 02 | Time: 3m 0s\n",
            "\tTrain Loss: 4.863 | Train PPL: 129.360\n",
            "\t Val. Loss: 5.282 |  Val. PPL: 196.688\n",
            "Epoch: 03 | Time: 3m 0s\n",
            "\tTrain Loss: 4.715 | Train PPL: 111.600\n",
            "\t Val. Loss: 5.362 |  Val. PPL: 213.078\n",
            "Epoch: 04 | Time: 3m 3s\n",
            "\tTrain Loss: 4.613 | Train PPL: 100.801\n",
            "\t Val. Loss: 5.407 |  Val. PPL: 222.966\n",
            "Epoch: 05 | Time: 3m 5s\n",
            "\tTrain Loss: 4.455 | Train PPL:  86.077\n",
            "\t Val. Loss: 5.523 |  Val. PPL: 250.493\n",
            "\n",
            "--- Обучение модели с MLP Attention ---\n",
            "Epoch: 01 | Time: 2m 59s\n",
            "\tTrain Loss: 5.501 | Train PPL: 244.852\n",
            "\t Val. Loss: 5.228 |  Val. PPL: 186.456\n",
            "Epoch: 02 | Time: 2m 57s\n",
            "\tTrain Loss: 4.858 | Train PPL: 128.733\n",
            "\t Val. Loss: 5.259 |  Val. PPL: 192.336\n",
            "Epoch: 03 | Time: 2m 59s\n",
            "\tTrain Loss: 4.716 | Train PPL: 111.736\n",
            "\t Val. Loss: 5.322 |  Val. PPL: 204.729\n",
            "Epoch: 04 | Time: 3m 0s\n",
            "\tTrain Loss: 4.601 | Train PPL:  99.544\n",
            "\t Val. Loss: 5.387 |  Val. PPL: 218.617\n",
            "Epoch: 05 | Time: 3m 0s\n",
            "\tTrain Loss: 4.447 | Train PPL:  85.365\n",
            "\t Val. Loss: 5.491 |  Val. PPL: 242.390\n"
          ]
        }
      ],
      "source": [
        "N_EPOCHS = 5 # Было 10\n",
        "CLIP = 1\n",
        "\n",
        "print(\"--- Обучение модели с Dot-Product Attention ---\")\n",
        "best_valid_loss_dot = float('inf')\n",
        "for epoch in range(N_EPOCHS):\n",
        "    start_time = time.time()\n",
        "    train_loss = train(model_dot, train_loader, optimizer_dot, criterion, CLIP)\n",
        "    valid_loss = evaluate(model_dot, valid_loader, criterion)\n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    if valid_loss < best_valid_loss_dot:\n",
        "        best_valid_loss_dot = valid_loss\n",
        "        torch.save(model_dot.state_dict(), 'dot-model.pt')\n",
        "\n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')\n",
        "\n",
        "print(\"\\n--- Обучение модели с MLP Attention ---\")\n",
        "best_valid_loss_mlp = float('inf')\n",
        "for epoch in range(N_EPOCHS):\n",
        "    start_time = time.time()\n",
        "    train_loss = train(model_mlp, train_loader, optimizer_mlp, criterion, CLIP)\n",
        "    valid_loss = evaluate(model_mlp, valid_loader, criterion)\n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    if valid_loss < best_valid_loss_mlp:\n",
        "        best_valid_loss_mlp = valid_loss\n",
        "        torch.save(model_mlp.state_dict(), 'mlp-model.pt')\n",
        "\n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "qSsbmgmyRbBK"
      },
      "outputs": [],
      "source": [
        "# Загрузка лучших весов\n",
        "model_dot.load_state_dict(torch.load('dot-model.pt'))\n",
        "model_mlp.load_state_dict(torch.load('mlp-model.pt'))\n",
        "\n",
        "def translate_sentence(sentence, model, src_vocab, trg_vocab, device, max_len=50):\n",
        "    model.eval()\n",
        "    tokens = [token.text.lower() for token in spacy_en(sentence)]\n",
        "    tokens = [src_vocab.word2idx.get(token, src_vocab.word2idx['<unk>']) for token in tokens]\n",
        "\n",
        "    src_tensor = torch.LongTensor(tokens).unsqueeze(1).to(device)\n",
        "    src_len = torch.LongTensor([len(tokens)]).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        encoder_outputs, hidden = model.encoder(src_tensor)\n",
        "\n",
        "    mask = model.create_mask(src_tensor)\n",
        "\n",
        "    trg_indexes = [trg_vocab.word2idx['<sos>']]\n",
        "\n",
        "    for i in range(max_len):\n",
        "        trg_tensor = torch.LongTensor([trg_indexes[-1]]).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output, hidden, _ = model.decoder(trg_tensor, hidden, encoder_outputs, mask)\n",
        "\n",
        "        pred_token = output.argmax(1).item()\n",
        "        trg_indexes.append(pred_token)\n",
        "\n",
        "        if pred_token == trg_vocab.word2idx['<eos>']:\n",
        "            break\n",
        "\n",
        "    trg_tokens = [trg_vocab.idx2word[i] for i in trg_indexes]\n",
        "    return trg_tokens[1:] # Убираем <sos>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  Проходим по датасету последовательно\n",
        "\n",
        "found_good_example = False\n",
        "example_idx = -1\n",
        "\n",
        "# Проходим по тестовому датасету с начала\n",
        "for i in range(len(test_dataset)):\n",
        "    src_sentence = src_test.dataset[i].tolist()\n",
        "\n",
        "    # Проверяем, есть ли <unk> в исходном предложении\n",
        "    if SRC_vocab.word2idx['<unk>'] not in src_sentence:\n",
        "        found_good_example = True\n",
        "        example_idx = i\n",
        "        break\n",
        "\n",
        "if not found_good_example:\n",
        "    print(\"К сожалению, не удалось найти ни одного примера без <unk> токенов во всем тестовом наборе.\")\n",
        "else:\n",
        "    # Если пример найден, продолжаем как раньше\n",
        "    trg_sentence = trg_test.dataset[example_idx].tolist()\n",
        "\n",
        "    # Преобразуем обратно в текст\n",
        "    src_text = ' '.join([SRC_vocab.idx2word[idx] for idx in src_sentence if idx not in [SRC_vocab.word2idx['<sos>'], SRC_vocab.word2idx['<eos>'], SRC_vocab.word2idx['<pad>']]])\n",
        "    trg_text = ' '.join([TRG_vocab.idx2word[idx] for idx in trg_sentence if idx not in [TRG_vocab.word2idx['<sos>'], TRG_vocab.word2idx['<eos>'], TRG_vocab.word2idx['<pad>']]])\n",
        "\n",
        "    print(f'Найден хороший пример (индекс {example_idx})!')\n",
        "    print(f'Исходное предложение (EN): {src_text}')\n",
        "    print(f'Эталонный перевод (RU): {trg_text}\\n')\n",
        "\n",
        "    # Перевод моделью с Dot-Product Attention\n",
        "    translation_dot = translate_sentence(src_text, model_dot, SRC_vocab, TRG_vocab, DEVICE)\n",
        "    print(f'Перевод (Dot-Product Attention): {\" \".join(translation_dot)}')\n",
        "\n",
        "    # Перевод моделью с MLP Attention\n",
        "    translation_mlp = translate_sentence(src_text, model_mlp, SRC_vocab, TRG_vocab, DEVICE)\n",
        "    print(f'Перевод (MLP Attention): {\" \".join(translation_mlp)}')"
      ],
      "metadata": {
        "id": "6QA4n3HUKyVo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5bea2e7-ad4b-42a3-a930-b01807710b38"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Найден хороший пример (индекс 0)!\n",
            "Исходное предложение (EN): go .\n",
            "Эталонный перевод (RU): марш!\n",
            "\n",
            "Перевод (Dot-Product Attention): я не <eos>\n",
            "Перевод (MLP Attention): я <eos>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  Оценка для Dot-Product на ТЕСТОВОЙ выборке\n",
        "# 1. Получаем только потерю (loss)\n",
        "test_loss_dot = evaluate(model_dot, test_loader, criterion)\n",
        "# 2. Вычисляем перплексию (PPL) вручную\n",
        "test_ppl_dot = math.exp(test_loss_dot)\n",
        "print(f'--- Test Loss (Dot-Product): {test_loss_dot:.3f} | Test PPL: {test_ppl_dot:7.3f}')\n",
        "\n",
        "#  Оценка для MLP Attention на ТЕСТОВОЙ выборке\n",
        "# 1. Получаем только потерю (loss)\n",
        "test_loss_mlp = evaluate(model_mlp, test_loader, criterion)\n",
        "# 2. Вычисляем перплексию (PPL) вручную\n",
        "test_ppl_mlp = math.exp(test_loss_mlp)\n",
        "print(f'--- Test Loss (MLP Attention): {test_loss_mlp:.3f} | Test PPL: {test_ppl_mlp:7.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1YwNP3-YT6zm",
        "outputId": "56b697f3-86a7-4793-8037-62931bd87838"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Test Loss (Dot-Product): 5.215 | Test PPL: 183.921\n",
            "--- Test Loss (MLP Attention): 5.225 | Test PPL: 185.920\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNXaQ+TbwOaTrmD79b/bQhS",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}