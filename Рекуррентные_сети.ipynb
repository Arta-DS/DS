{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMdZO6BwJhq+PWE1B6EzEBy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Arta-DS/DS/blob/main/%D0%A0%D0%B5%D0%BA%D1%83%D1%80%D1%80%D0%B5%D0%BD%D1%82%D0%BD%D1%8B%D0%B5_%D1%81%D0%B5%D1%82%D0%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Задание 1.**\n",
        "\n",
        "Обучите нейронную сеть решать шифр Цезаря.\n",
        "\n",
        "Что необходимо сделать:\n",
        "\n",
        "Написать алгоритм шифра Цезаря для генерации выборки (сдвиг на К каждой буквы. Например, при сдвиге на 2 буква “А” переходит в букву “В” и тп)\n",
        "Сделать нейронную сеть\n",
        "Обучить ее (вход - зашифрованная фраза, выход - дешифрованная фраза)\n",
        "Проверить качество\n",
        "\n",
        "**Задание 2.**\n",
        "\n",
        "Выполнить практическую работу из лекционного ноутбука.\n",
        "\n",
        "Построить RNN-ячейку на основе полносвязных слоев\n",
        "Применить построенную ячейку для генерации текста с выражениями героев сериала “Симпсоны”\n"
      ],
      "metadata": {
        "id": "e3Fd_n5OWjMM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import string\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, GlobalMaxPooling1D\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "import pandas as pd\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "bvQ_h5YXH2pC"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "N0W2PQIVHsTI"
      },
      "outputs": [],
      "source": [
        "ALPHABET = string.ascii_lowercase\n",
        "CHAR_TO_IDX = {ch: i for i, ch in enumerate(ALPHABET)}\n",
        "IDX_TO_CHAR = {i: ch for i, ch in enumerate(ALPHABET)}\n",
        "VOCAB_SIZE = len(ALPHABET)\n",
        "MAX_LEN = 10\n",
        "NUM_SHIFTS = 25  # сдвиги от 1 до 25"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def caesar_cipher(text, shift):\n",
        "    return ''.join(\n",
        "        IDX_TO_CHAR[(CHAR_TO_IDX[ch] + shift) % VOCAB_SIZE] if ch in CHAR_TO_IDX else ch\n",
        "        for ch in text.lower()\n",
        "    )\n",
        "\n",
        "def caesar_decipher(text, shift):\n",
        "    return ''.join(\n",
        "        IDX_TO_CHAR[(CHAR_TO_IDX[ch] - shift) % VOCAB_SIZE] if ch in CHAR_TO_IDX else ch\n",
        "        for ch in text.lower()\n",
        "    )"
      ],
      "metadata": {
        "id": "pYsPuAOvH1X1"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "WORD_LIST = [\n",
        "    \"hello\", \"world\", \"apple\", \"zebra\", \"python\", \"cipher\", \"secret\", \"model\", \"train\", \"learn\",\n",
        "    \"brain\", \"neural\", \"network\", \"letter\", \"shift\", \"decode\", \"encode\", \"attack\", \"system\", \"input\",\n",
        "    \"output\", \"vector\", \"matrix\", \"tensor\", \"layer\", \"weight\", \"bias\", \"epoch\", \"batch\", \"data\",\n",
        "    \"text\", \"word\", \"code\", \"logic\", \"solve\", \"answer\", \"right\", \"wrong\", \"quick\", \"brown\",\n",
        "    \"jumps\", \"over\", \"lazy\", \"dog\", \"house\", \"green\", \"black\", \"white\", \"color\", \"music\",\n",
        "    \"water\", \"earth\", \"flame\", \"light\", \"sound\", \"voice\", \"image\", \"pixel\", \"frame\", \"video\"\n",
        "]\n",
        "WORD_LIST = [w.lower() for w in WORD_LIST if w.isalpha() and 3 <= len(w) <= MAX_LEN]"
      ],
      "metadata": {
        "id": "cmvRDOxFIADC"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_shift_dataset(n_samples=30000):\n",
        "    X_texts = []\n",
        "    y_shifts = []\n",
        "    for _ in range(n_samples):\n",
        "        plain = np.random.choice(WORD_LIST)\n",
        "        shift = np.random.randint(1, 26)  # 1..25\n",
        "        cipher = caesar_cipher(plain, shift)\n",
        "        X_texts.append(cipher.ljust(MAX_LEN)[:MAX_LEN])\n",
        "        y_shifts.append(shift - 1)  # классы от 0 до 24\n",
        "    return X_texts, np.array(y_shifts)"
      ],
      "metadata": {
        "id": "g1iDbCVjICoA"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def text_to_tensor(texts):\n",
        "    tensor = np.zeros((len(texts), MAX_LEN, VOCAB_SIZE), dtype=np.float32)\n",
        "    for i, text in enumerate(texts):\n",
        "        for j, ch in enumerate(text):\n",
        "            if ch in CHAR_TO_IDX:\n",
        "                tensor[i, j, CHAR_TO_IDX[ch]] = 1.0\n",
        "    return tensor"
      ],
      "metadata": {
        "id": "_n4hiZiLIFCs"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = Input(shape=(MAX_LEN, VOCAB_SIZE))\n",
        "x = LSTM(128, return_sequences=True)(inputs)\n",
        "x = GlobalMaxPooling1D()(x)  # сводим к вектору\n",
        "x = Dense(64, activation='relu')(x)\n",
        "outputs = Dense(NUM_SHIFTS, activation='softmax')(x)  # 25 классов\n",
        "\n",
        "shift_model = Model(inputs, outputs)\n",
        "shift_model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "shift_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "id": "CT9Ck_raL570",
        "outputId": "06c12ccd-55e5-4dfa-bead-de8919e2edf2"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m26\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m79,360\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_max_pooling1d            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m)             │         \u001b[38;5;34m1,625\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">79,360</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_max_pooling1d            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,625</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m89,241\u001b[0m (348.60 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">89,241</span> (348.60 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m89,241\u001b[0m (348.60 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">89,241</span> (348.60 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Генерация данных...\")\n",
        "X_texts, y_shifts = generate_shift_dataset(30000)\n",
        "X = text_to_tensor(X_texts)\n",
        "\n",
        "print(\"Обучение модели предсказания сдвига...\")\n",
        "shift_model.fit(X, y_shifts, batch_size=64, epochs=30, validation_split=0.1)\n",
        "\n",
        "# === Дешифровка с использованием предсказанного сдвига ===\n",
        "def decrypt_with_shift_model(cipher_text):\n",
        "    padded = cipher_text.ljust(MAX_LEN)[:MAX_LEN]\n",
        "    inp = text_to_tensor([padded])\n",
        "    pred_shift_idx = np.argmax(shift_model.predict(inp, verbose=0), axis=1)[0]\n",
        "    pred_shift = pred_shift_idx + 1  # обратно к 1..25\n",
        "    return caesar_decipher(cipher_text, pred_shift)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "liMtGpD5L_pb",
        "outputId": "7b425fa2-dcf5-43b3-e86d-ffea5d953636"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Генерация данных...\n",
            "Обучение модели предсказания сдвига...\n",
            "Epoch 1/30\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 23ms/step - accuracy: 0.1701 - loss: 2.8075 - val_accuracy: 0.4960 - val_loss: 1.6235\n",
            "Epoch 2/30\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - accuracy: 0.5790 - loss: 1.3710 - val_accuracy: 0.7623 - val_loss: 0.8066\n",
            "Epoch 3/30\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - accuracy: 0.8389 - loss: 0.6256 - val_accuracy: 0.9360 - val_loss: 0.3044\n",
            "Epoch 4/30\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - accuracy: 0.9722 - loss: 0.2076 - val_accuracy: 1.0000 - val_loss: 0.0749\n",
            "Epoch 5/30\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - accuracy: 0.9994 - loss: 0.0580 - val_accuracy: 1.0000 - val_loss: 0.0289\n",
            "Epoch 6/30\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0228 - val_accuracy: 1.0000 - val_loss: 0.0144\n",
            "Epoch 7/30\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0119 - val_accuracy: 1.0000 - val_loss: 0.0084\n",
            "Epoch 8/30\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.0072 - val_accuracy: 1.0000 - val_loss: 0.0054\n",
            "Epoch 9/30\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0047 - val_accuracy: 1.0000 - val_loss: 0.0037\n",
            "Epoch 10/30\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 1.0000 - val_loss: 0.0026\n",
            "Epoch 11/30\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 1.0000 - val_loss: 0.0018\n",
            "Epoch 12/30\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 1.0000 - val_loss: 0.0013\n",
            "Epoch 13/30\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 1.0000 - val_loss: 9.8418e-04\n",
            "Epoch 14/30\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 8.6876e-04 - val_accuracy: 1.0000 - val_loss: 7.3313e-04\n",
            "Epoch 15/30\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 6.4668e-04 - val_accuracy: 1.0000 - val_loss: 5.5414e-04\n",
            "Epoch 16/30\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 4.8659e-04 - val_accuracy: 1.0000 - val_loss: 4.1964e-04\n",
            "Epoch 17/30\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 3.7022e-04 - val_accuracy: 1.0000 - val_loss: 3.2103e-04\n",
            "Epoch 18/30\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 2.8482e-04 - val_accuracy: 1.0000 - val_loss: 2.4706e-04\n",
            "Epoch 19/30\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 2.2027e-04 - val_accuracy: 1.0000 - val_loss: 1.8928e-04\n",
            "Epoch 20/30\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 1.6925e-04 - val_accuracy: 1.0000 - val_loss: 1.4654e-04\n",
            "Epoch 21/30\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 1.3160e-04 - val_accuracy: 1.0000 - val_loss: 1.1334e-04\n",
            "Epoch 22/30\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 1.0010e-04 - val_accuracy: 1.0000 - val_loss: 8.8046e-05\n",
            "Epoch 23/30\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 7.8143e-05 - val_accuracy: 1.0000 - val_loss: 6.8501e-05\n",
            "Epoch 24/30\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 6.0457e-05 - val_accuracy: 1.0000 - val_loss: 5.3189e-05\n",
            "Epoch 25/30\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 4.7208e-05 - val_accuracy: 1.0000 - val_loss: 4.1512e-05\n",
            "Epoch 26/30\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 3.6949e-05 - val_accuracy: 1.0000 - val_loss: 3.2651e-05\n",
            "Epoch 27/30\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 2.9154e-05 - val_accuracy: 1.0000 - val_loss: 2.5630e-05\n",
            "Epoch 28/30\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 2.2711e-05 - val_accuracy: 1.0000 - val_loss: 2.0133e-05\n",
            "Epoch 29/30\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 1.7919e-05 - val_accuracy: 1.0000 - val_loss: 1.5879e-05\n",
            "Epoch 30/30\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 1.4133e-05 - val_accuracy: 1.0000 - val_loss: 1.2453e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Тестирование ===\n",
        "test_cases = [\n",
        "    (\"hello\", 3),\n",
        "    (\"world\", 7),\n",
        "    (\"python\", 13),\n",
        "    (\"secret\", 25),\n",
        "    (\"neural\", 10)\n",
        "]\n",
        "\n",
        "print(\"\\n=== Тестирование ===\")\n",
        "for plain, shift in test_cases:\n",
        "    cipher = caesar_cipher(plain, shift)\n",
        "    decrypted = decrypt_with_shift_model(cipher)\n",
        "    success = decrypted == plain\n",
        "    print(f\"Оригинал: {plain:8} | Сдвиг: {shift:2} | Шифр: {cipher:10} | Расшифровка: {decrypted:8} | Успех: {success}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTB0VipXL_2b",
        "outputId": "a30446e5-1814-47a4-8e46-35d3c1f22e47"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Тестирование ===\n",
            "Оригинал: hello    | Сдвиг:  3 | Шифр: khoor      | Расшифровка: hello    | Успех: True\n",
            "Оригинал: world    | Сдвиг:  7 | Шифр: dvysk      | Расшифровка: world    | Успех: True\n",
            "Оригинал: python   | Сдвиг: 13 | Шифр: clguba     | Расшифровка: python   | Успех: True\n",
            "Оригинал: secret   | Сдвиг: 25 | Шифр: rdbqds     | Расшифровка: secret   | Успех: True\n",
            "Оригинал: neural   | Сдвиг: 10 | Шифр: xoebkv     | Расшифровка: neural   | Успех: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "=============================================================================="
      ],
      "metadata": {
        "id": "Bz4Uf1zBWMnz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Загрузка и подготовка данных\n",
        "df = pd.read_csv('simpsons_script_lines.csv')\n",
        "phrases = df['normalized_text'].dropna().tolist()\n",
        "\n",
        "# Оставим только строчные буквы и пробел\n",
        "CHARS = set('abcdefghijklmnopqrstuvwxyz ')\n",
        "INDEX_TO_CHAR = ['<PAD>', '<UNK>'] + sorted(CHARS)  # 0: PAD, 1: UNK, 2+: символы\n",
        "CHAR_TO_INDEX = {ch: i for i, ch in enumerate(INDEX_TO_CHAR)}\n",
        "VOCAB_SIZE = len(INDEX_TO_CHAR)\n",
        "\n",
        "print(f\"Размер словаря: {VOCAB_SIZE}\")  # должно быть 28 (26 букв + пробел + 2 спецсимвола)\n",
        "\n",
        "# Преобразуем фразы в последовательности индексов\n",
        "MAX_LEN = 50\n",
        "sequences = []\n",
        "for ph in phrases:\n",
        "    if not isinstance(ph, str):\n",
        "        continue\n",
        "    # Оставляем только разрешённые символы\n",
        "    clean_ph = ''.join(ch if ch in CHARS else ' ' for ch in ph.lower())\n",
        "    if len(clean_ph) < 2:\n",
        "        continue\n",
        "    seq = [CHAR_TO_INDEX.get(ch, CHAR_TO_INDEX['<UNK>']) for ch in clean_ph]\n",
        "    sequences.append(seq)\n",
        "\n",
        "# Создаём тензор X с паддингом\n",
        "X = torch.full((len(sequences), MAX_LEN), CHAR_TO_INDEX['<PAD>'], dtype=torch.long)\n",
        "for i, seq in enumerate(sequences):\n",
        "    truncated = seq[:MAX_LEN]\n",
        "    X[i, :len(truncated)] = torch.tensor(truncated, dtype=torch.long)\n",
        "\n",
        "print(f\"Форма данных: {X.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zN4sgR7WNVqd",
        "outputId": "76048c78-577d-433a-f143-349131775ddf"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3031060131.py:2: DtypeWarning: Columns (4,5,6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv('simpsons_script_lines.csv')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Размер словаря: 29\n",
            "Форма данных: torch.Size([132075, 50])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  2. Ручная RNN-ячейка на основе полносвязных слоёв\n",
        "class SimpleRNNCell(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        # W_hh * h_{t-1} + W_xh * x_t + b\n",
        "        self.weight_hh = nn.Linear(hidden_size, hidden_size, bias=True)\n",
        "        self.weight_xh = nn.Linear(input_size, hidden_size, bias=False)  # bias уже в weight_hh\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        # x: (batch, input_size)\n",
        "        # hidden: (batch, hidden_size)\n",
        "        h_new = torch.tanh(self.weight_hh(hidden) + self.weight_xh(x))\n",
        "        return h_new"
      ],
      "metadata": {
        "id": "G2EMNrBEV5xJ"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  3. Многослойная RNN на основе нашей ячейки\n",
        "class ManualRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers=1):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.layers = nn.ModuleList([\n",
        "            SimpleRNNCell(input_size if i == 0 else hidden_size, hidden_size)\n",
        "            for i in range(num_layers)\n",
        "        ])\n",
        "\n",
        "    def forward(self, x, hidden=None):\n",
        "        # x: (batch, seq_len, input_size)\n",
        "        batch, seq_len, _ = x.shape\n",
        "        if hidden is None:\n",
        "            hidden = [torch.zeros(batch, self.hidden_size, device=x.device) for _ in range(self.num_layers)]\n",
        "        outputs = []\n",
        "        for t in range(seq_len):\n",
        "            inp = x[:, t, :]  # (batch, input_size)\n",
        "            for layer_idx, layer in enumerate(self.layers):\n",
        "                inp = layer(inp, hidden[layer_idx])\n",
        "                hidden[layer_idx] = inp\n",
        "            outputs.append(inp)\n",
        "        outputs = torch.stack(outputs, dim=1)  # (batch, seq_len, hidden_size)\n",
        "        return outputs, hidden"
      ],
      "metadata": {
        "id": "kge-VE3yV54n"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  4. Полная модель для генерации текста\n",
        "class SimpsonsRNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim=30, hidden_size=128, num_layers=1):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=CHAR_TO_INDEX['<PAD>'])\n",
        "        self.rnn = ManualRNN(embed_dim, hidden_size, num_layers)\n",
        "        self.fc_out = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "    def forward(self, x, hidden=None):\n",
        "        # x: (batch, seq_len)\n",
        "        embedded = self.embedding(x)  # (batch, seq_len, embed_dim)\n",
        "        rnn_out, hidden = self.rnn(embedded, hidden)\n",
        "        logits = self.fc_out(rnn_out)  # (batch, seq_len, vocab_size)\n",
        "        return logits, hidden"
      ],
      "metadata": {
        "id": "WWfHCNiRV-iZ"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  5. Обучение\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = SimpsonsRNN(VOCAB_SIZE, embed_dim=30, hidden_size=128, num_layers=1).to(device)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=CHAR_TO_INDEX['<PAD>'])\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
        "\n",
        "# Обучение\n",
        "EPOCHS = 20\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "for ep in range(EPOCHS):\n",
        "    start = time.time()\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    num_batches = 0\n",
        "\n",
        "    # Перемешиваем индексы\n",
        "    indices = torch.randperm(X.size(0))\n",
        "\n",
        "    for i in range(0, len(indices), BATCH_SIZE):\n",
        "        batch_indices = indices[i:i+BATCH_SIZE]\n",
        "        batch = X[batch_indices].to(device)\n",
        "\n",
        "        # X_batch: все символы, кроме последнего\n",
        "        # Y_batch: все символы, кроме первого\n",
        "        X_batch = batch[:, :-1]\n",
        "        Y_batch = batch[:, 1:].contiguous()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        logits, _ = model(X_batch)\n",
        "        # logits: (batch, seq_len, vocab_size) -> (batch*seq_len, vocab_size)\n",
        "        # Y_batch: (batch, seq_len) -> (batch*seq_len,)\n",
        "        loss = criterion(logits.view(-1, VOCAB_SIZE), Y_batch.view(-1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        num_batches += 1\n",
        "\n",
        "    avg_loss = total_loss / num_batches\n",
        "    print(f\"Epoch {ep+1}/{EPOCHS}. Time: {time.time() - start:.2f}s, Loss: {avg_loss:.4f}\")\n",
        "\n",
        "# === 6. Генерация текста ===\n",
        "def generate_text(seed_text, max_length=50, temperature=1.0):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        # Преобразуем seed в индексы\n",
        "        current_seq = [CHAR_TO_INDEX.get(ch, CHAR_TO_INDEX['<UNK>']) for ch in seed_text.lower() if ch in CHARS or ch == ' ']\n",
        "        if not current_seq:\n",
        "            current_seq = [CHAR_TO_INDEX['h']]  # fallback\n",
        "\n",
        "        input_tensor = torch.tensor([current_seq], dtype=torch.long).to(device)\n",
        "        hidden = None\n",
        "\n",
        "        # Прогоняем seed через модель, чтобы инициализировать hidden state\n",
        "        _, hidden = model(input_tensor, hidden)\n",
        "        last_char = input_tensor[0, -1].item()\n",
        "\n",
        "        generated = list(seed_text)\n",
        "\n",
        "        for _ in range(max_length):\n",
        "            # Подаём последний символ\n",
        "            input_char = torch.tensor([[last_char]], device=device)\n",
        "            logits, hidden = model(input_char, hidden)\n",
        "\n",
        "            # Применяем температуру\n",
        "            logits = logits.squeeze() / temperature\n",
        "            probs = torch.softmax(logits, dim=-1)\n",
        "\n",
        "            # Сэмплируем следующий символ\n",
        "            next_char_idx = torch.multinomial(probs, 1).item()\n",
        "\n",
        "            if next_char_idx == CHAR_TO_INDEX['<PAD>']:\n",
        "                break\n",
        "\n",
        "            next_char = INDEX_TO_CHAR[next_char_idx]\n",
        "            if next_char == '<UNK>':\n",
        "                continue\n",
        "\n",
        "            generated.append(next_char)\n",
        "            last_char = next_char_idx\n",
        "\n",
        "            # Остановка при генерации \"мусора\"\n",
        "            if len(generated) > 5 and all(c not in CHARS for c in generated[-5:]):\n",
        "                break\n",
        "\n",
        "        return ''.join(generated)\n",
        "\n",
        "# 7. Тестирование генерации\n",
        "print(\"\\n=== Генерация текста в стиле Симпсонов ===\")\n",
        "seeds = [\"homer\", \"lisa\", \"marge\", \"bart\", \"doh\", \"hey\", \"what\"]\n",
        "for seed in seeds:\n",
        "    gen = generate_text(seed, max_length=40, temperature=0.8)\n",
        "    print(f\"Seed: '{seed}' → '{gen}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5s1zSjRUQRah",
        "outputId": "3fd23104-1b8b-4f08-d702-c03f321c334c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2264100089.py:8: DtypeWarning: Columns (4,5,6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv('simpsons_script_lines.csv')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Размер словаря: 29\n",
            "Форма данных: torch.Size([132075, 50])\n",
            "Epoch 1/20. Time: 58.58s, Loss: 1.6826\n",
            "Epoch 2/20. Time: 58.15s, Loss: 1.5212\n",
            "Epoch 3/20. Time: 57.07s, Loss: 1.4953\n",
            "Epoch 4/20. Time: 58.14s, Loss: 1.4828\n",
            "Epoch 5/20. Time: 58.21s, Loss: 1.4758\n",
            "Epoch 6/20. Time: 58.69s, Loss: 1.4707\n",
            "Epoch 7/20. Time: 59.16s, Loss: 1.4678\n",
            "Epoch 8/20. Time: 57.90s, Loss: 1.4647\n",
            "Epoch 9/20. Time: 56.77s, Loss: 1.4632\n",
            "Epoch 10/20. Time: 57.41s, Loss: 1.4612\n",
            "Epoch 11/20. Time: 58.88s, Loss: 1.4607\n",
            "Epoch 12/20. Time: 56.93s, Loss: 1.4617\n",
            "Epoch 13/20. Time: 57.68s, Loss: 1.4947\n",
            "Epoch 14/20. Time: 57.91s, Loss: 1.4683\n",
            "Epoch 15/20. Time: 58.12s, Loss: 1.4624\n",
            "Epoch 16/20. Time: 57.51s, Loss: 1.4612\n",
            "Epoch 17/20. Time: 57.37s, Loss: 1.4614\n",
            "Epoch 18/20. Time: 56.84s, Loss: 1.4742\n",
            "Epoch 19/20. Time: 58.05s, Loss: 1.4674\n",
            "Epoch 20/20. Time: 58.66s, Loss: 1.4638\n",
            "\n",
            "=== Генерация текста в стиле Симпсонов ===\n",
            "Seed: 'homer' → 'homery are we get another for thous po thous '\n",
            "Seed: 'lisa' → 'lisaaay mavie springfiel are you and yes thi'\n",
            "Seed: 'marge' → 'marged the repent down are a us tiever on me '\n",
            "Seed: 'bart' → 'bartas ratch are you a heaking in the minus '\n",
            "Seed: 'doh' → 'doh you can be exciting about here and we c'\n",
            "Seed: 'hey' → 'hey if you ca money where weve got a please'\n",
            "Seed: 'what' → 'what and and limiting heres to fouldnt me al'\n"
          ]
        }
      ]
    }
  ]
}