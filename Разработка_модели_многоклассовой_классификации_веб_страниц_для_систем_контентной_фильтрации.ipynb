# ПОЯСНИТЕЛЬНАЯ ЗАПИСКА

## К дипломному проекту по курсу "Deep Learning"

### Тема: Разработка модели многоклассовой классификации веб-страниц для систем контентной фильтрации

**Выполнила:** Артамонова Татьяна  
**Образовательная организация:** Нетология  
**Год:** 2025

---

## СОДЕРЖАНИЕ

1. Введение и постановка задачи .................................................. 3
2. Описание данных и их особенностей .......................................... 4
3. Описание обработки данных и разделение на трейн и тест ............. 5
4. Описание возможных решений и планируемая архитектура ............. 6
5. Описание обучения ................................................................ 7
6. Описание итогового результата и применение на практике ............ 8
7. Заключение с выводами и планами на дальнейшее развитие ........... 9
8. Список литературы ................................................................ 10

---

## 1. ВВЕДЕНИЕ И ПОСТАНОВКА ЗАДАЧИ

### 1.1. Актуальность темы

В современном интернете ежедневно создаются миллионы новых веб-страниц. Автоматическая категоризация контента является критически важной задачей для систем контентной фильтрации, родительского контроля, поисковых систем и систем рекомендаций. Ручная классификация такого объема данных физически невозможна, а существующие коммерческие решения могут быть дорогостоящими и недостаточно точными.

### 1.2. Цель проекта

Разработать модель машинного обучения для автоматической классификации веб-страниц по их текстовому содержимому с высокой точностью определения одной из 16 категорий контента.

### 1.3. Задачи проекта

1. Провести анализ датасета и выявить особенности данных
2. Реализовать предобработку текстовых данных
3. Разработать и обучить несколько моделей классификации
4. Сравнить результаты и выбрать оптимальное решение
5. Оценить качество работы модели на тестовых данных

### 1.4. Метрики качества

В качестве основной метрики выбран **Macro F1-score** с целевым значением более 0.90. Данная метрика была выбрана по следующим причинам:

- Она одинаково учитывает качество предсказаний для всех классов
- Не дает модели возможность игнорировать редкие, но важные категории
- Обеспечивает сбалансированную оценку точности и полноты
- Является стандартом для задач с несбалансированными классами

---

## 2. ОПИСАНИЕ ДАННЫХ И ИХ ОСОБЕННОСТЕЙ

### 2.1. Источник данных

Для обучения моделей использован датасет "Website Classification" платформы Kaggle, содержащий 1408 записей веб-страниц с размеченными категориями.

**Ссылка на датасет:** [Kaggle - Website Classification](https://www.kaggle.com/datasets/hetulmehta/website-classification)

### 2.2. Структура данных

Датасет содержит следующие поля:
- **website_url** - URL веб-страницы
- **cleaned_website_text** - очищенный текстовый контент страницы
- **Category** - категория веб-страницы (целевая переменная)

### 2.3. Категории контента

Датасет включает 16 различных категорий:

1. Travel (Путешествия)
2. Business/Corporate (Бизнес/Корпоративные)
3. E-Commerce (Электронная коммерция)
4. Computers & Technology (Компьютеры и технологии)
5. Health (Здоровье)
6. News (Новости)
7. Sports (Спорт)
8. Games (Игры)
9. Shopping (Покупки)
10. Education (Образование)
11. Social Media (Социальные сети)
12. Food (Еда)
13. Streaming Services (Стриминговые сервисы)
14. Arts & Entertainment (Искусство и развлечения)
15. Forums (Форумы)
16. Adult (Взрослый контент)

### 2.4. Основные особенности данных

**Дисбаланс классов:** Наблюдается значительный дисбаланс в представленности категорий. Наиболее частые категории (Travel, Business/Corporate) содержат в 5-8 раз больше примеров, чем редкие категории (Forums, Adult).

**Качество текста:** Текстовые данные предварительно очищены от HTML-тегов, специальных символов и нормализованы.

**Длина текстов:** Тексты имеют различную длину - от нескольких десятков до нескольких тысяч слов, что отражает реальное разнообразие веб-контента.

**Языковые особенности:** Все тексты представлены на английском языке.

---

## 3. ОПИСАНИЕ ОБРАБОТКИ ДАННЫХ И РАЗДЕЛЕНИЕ НА ТРЕЙН И ТЕСТ

### 3.1. Предобработка данных

Текстовые данные прошли следующие этапы обработки:

1. **Приведение к нижнему регистру** - для унификации написания слов
2. **Удаление стоп-слов** - исключение частотных слов без семантической нагрузки (the, is, at и т.д.)
3. **Лемматизация** - приведение слов к начальной форме для уменьшения размерности
4. **Удаление чисел и специальных символов** - очистка от нерелевантной информации

### 3.2. Разделение данных

Данные были разделены на обучающую и тестовую выборки в соотношении **80% / 20%** с использованием стратифицированного разбиения:

- **Обучающая выборка:** 1126 примеров (80%)
- **Тестовая выборка:** 282 примера (20%)

Стратификация гарантирует, что соотношение классов в обеих выборках остается одинаковым, что особенно важно при работе с несбалансированными данными.

### 3.3. Векторизация текста

Для преобразования текста в числовой формат использовались следующие подходы:

**Для baseline модели (TF-IDF):**
- Метод: TF-IDF (Term Frequency - Inverse Document Frequency)
- Максимальное количество признаков: 5000
- Учет биграмм: да (ngram_range=(1,2))
- Минимальная частота документов: 2

**Для BERT модели:**
- Токенизатор: bert-base-uncased
- Максимальная длина последовательности: 128 токенов
- Padding и truncation применены для унификации длины

---

## 4. ОПИСАНИЕ ВОЗМОЖНЫХ РЕШЕНИЙ И ПЛАНИРУЕМАЯ АРХИТЕКТУРА

### 4.1. Выбор подходов

Для решения задачи были выбраны два различных подхода, представляющих классическое машинное обучение и глубокое обучение:

### 4.2. Эксперимент 1: Baseline модель (TF-IDF + LinearSVC)

**Архитектура:**
- Векторизация: TF-IDF с 5000 признаками
- Классификатор: LinearSVC (Support Vector Classifier)
- Параметры: C=1.0, max_iter=1000

**Обоснование выбора:**
- Простота и интерпретируемость модели
- Быстрое обучение и предсказание
- Хорошо работает с текстовыми данными
- Устойчивость к дисбалансу классов
- Низкие требования к вычислительным ресурсам

### 4.3. Эксперимент 2: Deep Learning подход (BERT)

**Архитектура:**
- Базовая модель: BERT (bert-base-uncased)
- Fine-tuning: полное дообучение последних слоев
- Классификационная голова: Linear layer (768 → 16 классов)
- Dropout: 0.1 для регуляризации

**Обоснование выбора:**
- Способность понимать контекст слов
- Предобученная модель на большом корпусе текстов
- State-of-the-art результаты в NLP задачах
- Возможность transfer learning

### 4.4. Гипотеза исследования

Предполагалось, что BERT как более сложная модель с пониманием контекста покажет лучшие результаты, особенно на сложных, семантически близких категориях. Однако необходимо проверить, оправдывает ли улучшение качества увеличение сложности и требований к ресурсам.

---

## 5. ОПИСАНИЕ ОБУЧЕНИЯ

### 5.1. Обучение baseline модели (TF-IDF + LinearSVC)

**Параметры обучения:**
- Метод оптимизации: SGD (Stochastic Gradient Descent)
- Функция потерь: Hinge loss
- Время обучения: около 2 секунд

**Процесс обучения:**
1. Векторизация текстов с помощью TF-IDF
2. Обучение LinearSVC на обучающей выборке
3. Кросс-валидация для подбора параметра C
4. Финальное обучение на всей обучающей выборке

### 5.2. Обучение BERT модели

**Параметры обучения:**
- Оптимизатор: AdamW
- Learning rate: 2e-5 с линейным decay
- Batch size: 16
- Количество эпох: 3
- Функция потерь: CrossEntropyLoss
- Время обучения: около 45 минут на GPU

**Процесс обучения:**
1. Загрузка предобученной модели bert-base-uncased
2. Добавление классификационной головы
3. Fine-tuning на обучающей выборке
4. Мониторинг loss и accuracy на валидационной выборке
5. Сохранение лучшей модели по validation accuracy

**Особенности обучения:**
- Использование gradient accumulation для увеличения effective batch size
- Применение learning rate warmup (10% от общего количества шагов)
- Early stopping при отсутствии улучшения на валидации

### 5.3. Проблемы и их решение

**Проблема:** Переобучение BERT на малом датасете  
**Решение:** Применение dropout (0.1) и уменьшение количества эпох до 3

**Проблема:** Медленное обучение BERT  
**Решение:** Использование GPU и оптимизация batch size

---

## 6. ОПИСАНИЕ ИТОГОВОГО РЕЗУЛЬТАТА И ПРИМЕНЕНИЕ НА ПРАКТИКЕ

### 6.1. Результаты экспериментов

**Baseline модель (TF-IDF + LinearSVC):**
- **Macro F1-score: 0.93**
- Precision: 0.94
- Recall: 0.93
- Время предсказания: <1 мс на образец

**BERT модель:**
- **Macro F1-score: 0.87**
- Precision: 0.88
- Recall: 0.87
- Время предсказания: ~50 мс на образец

### 6.2. Сравнительный анализ

**Преимущества baseline модели:**
- Более высокая точность (на 6% выше по Macro F1)
- Значительно быстрее обучение и inference
- Лучше справляется с редкими классами (Forums, Adult)
- Проще в развертывании и поддержке
- Не требует GPU для работы

**Преимущества BERT модели:**
- Лучше обрабатывает семантически близкие категории
- Понимает контекст и длинные зависимости
- Потенциал для улучшения при увеличении датасета

### 6.3. Анализ ошибок

**Confusion Matrix анализ показал:**
- Baseline модель делает меньше ошибок на всех категориях
- BERT имеет критический провал на категории "Forums" (0 верных предсказаний)
- Обе модели путают семантически близкие категории (E-Commerce ↔ Shopping)

### 6.4. Выбор финальной модели

**Итоговое решение:** В качестве production модели выбрана **baseline модель TF-IDF + LinearSVC**

**Обоснование:**
1. Достигнута и превышена целевая метрика (0.93 > 0.90)
2. Более стабильная работа на редких классах
3. Значительно меньшие требования к ресурсам
4. Быстрое время отклика
5. Простота интеграции и обслуживания

### 6.5. Применение на практике

**Возможные сценарии использования:**

1. **Системы родительского контроля** - фильтрация нежелательного контента для детей
2. **Поисковые системы** - автоматическая категоризация новых сайтов для улучшения поиска
3. **Рекламные платформы** - определение категории сайта для таргетинга рекламы
4. **Корпоративные firewall** - блокировка доступа к определенным категориям сайтов
5. **Системы мониторинга бренда** - отслеживание упоминаний в различных категориях сайтов

**Технические требования для внедрения:**
- Python 3.8+
- scikit-learn
- Память: ~100 MB для модели
- CPU: любой современный процессор
- Время отклика: <10 мс

---

## 7. ЗАКЛЮЧЕНИЕ С ВЫВОДАМИ И ПЛАНАМИ НА ДАЛЬНЕЙШЕЕ РАЗВИТИЕ

### 7.1. Основные выводы

1. **Цель проекта достигнута:** Разработана модель с Macro F1-score = 0.93, что превышает целевое значение 0.90

2. **Неожиданный результат:** Классическая модель машинного обучения показала лучший результат, чем современная нейросетевая архитектура BERT

3. **Причины успеха baseline модели:**
   - Для небольших датасетов (1408 примеров) простые модели могут быть эффективнее
   - TF-IDF хорошо захватывает уникальные слова-маркеры для каждой категории
   - LinearSVC устойчив к переобучению на малых данных
   - Меньше параметров = меньше риск переобучения

4. **Главный вывод проекта:** Сложность модели не всегда коррелирует с качеством результата. Для задач с ограниченными данными классические методы машинного обучения могут быть предпочтительнее глубокого обучения.

### 7.2. Практическая значимость

- Создана работающая система классификации веб-страниц
- Модель готова к практическому применению без доработок
- Низкие требования к ресурсам позволяют развернуть модель на любом сервере
- Быстрое время отклика обеспечивает real-time классификацию

### 7.3. Планы на дальнейшее развитие

**Краткосрочные планы (1-3 месяца):**

1. **Расширение датасета**
   - Увеличить размер датасета до 10,000+ примеров
   - Добавить больше примеров для редких категорий
   - Провести повторный эксперимент с BERT на большем объеме данных

2. **Создание веб-интерфейса**
   - Разработать демо-приложение с использованием Streamlit
   - Добавить визуализацию уверенности модели
   - Реализовать batch processing для массовой классификации

3. **Оптимизация производительности**
   - Экспортировать модель в ONNX формат для ускорения inference
   - Реализовать кэширование частых запросов
   - Добавить API endpoint для интеграции с другими системами

**Среднесрочные планы (3-6 месяцев):**

4. **Расширение категорий**
   - Добавить новые специализированные категории (Криптовалюты, AI/ML, Cybersecurity)
   - Создать иерархическую систему категорий (категории → подкатегории)
   - Реализовать multi-label классификацию (сайт может принадлежать нескольким категориям)

5. **Мультиязычная поддержка**
   - Адаптировать модель для работы с русским языком
   - Добавить автоматическое определение языка
   - Создать отдельные модели для разных языков

6. **Улучшение качества**
   - Провести ансамблирование нескольких моделей
   - Добавить дополнительные признаки (URL structure, meta tags)
   - Реализовать active learning для улучшения на сложных примерах

**Долгосрочные планы (6-12 месяцев):**

7. **Коммерциализация**
   - Создать SaaS продукт для B2B клиентов
   - Разработать pricing модель
   - Получить обратную связь от первых пользователей

8. **Исследование новых подходов**
   - Попробовать более легкие версии BERT (DistilBERT, TinyBERT)
   - Исследовать few-shot learning для новых категорий
   - Экспериментировать с prompt-based методами (GPT-based classification)

### 7.4. Ограничения текущего решения

1. Работает только с английским языком
2. Требует наличия текстового контента (не работает с изображениями)
3. Может быть неточной для новых, не представленных в обучении тем
4. Не учитывает структуру HTML и визуальное оформление сайта

### 7.5. Заключительное слово

Проект успешно продемонстрировал, что задача автоматической классификации веб-страниц может быть эффективно решена с использованием классических методов машинного обучения. Полученная модель показывает высокую точность и готова к практическому применению. Результаты проекта подтверждают важность тщательного выбора подхода в зависимости от объема данных и требований к системе.

---

## 8. СПИСОК ЛИТЕРАТУРЫ

1. **Scikit-learn Documentation** - Machine Learning in Python  
   https://scikit-learn.org/stable/

2. **Devlin J. et al.** (2019) "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"  
   arXiv:1810.04805

3. **Salton G., Buckley C.** (1988) "Term-weighting approaches in automatic text retrieval"  
   Information Processing & Management, 24(5), 513-523

4. **Joachims T.** (1998) "Text categorization with support vector machines: Learning with many relevant features"  
   European Conference on Machine Learning, pp. 137-142

5. **Kaggle Dataset** - Website Classification  
   https://www.kaggle.com/datasets/hetulmehta/website-classification

6. **Hugging Face Transformers** - State-of-the-art Natural Language Processing  
   https://huggingface.co/docs/transformers/

7. **Manning C.D., Raghavan P., Schütze H.** (2008) "Introduction to Information Retrieval"  
   Cambridge University Press

8. **Chollet F.** (2018) "Deep Learning with Python"  
   Manning Publications

9. **Jurafsky D., Martin J.H.** (2023) "Speech and Language Processing" (3rd edition)  
   https://web.stanford.edu/~jurafsky/slp3/

10. **Python Documentation** - Natural Language Toolkit (NLTK)  
    https://www.nltk.org/

---

**Ссылка на код проекта:**  
https://www.kaggle.com/code/carissima95/multi-class-classification-of-web-pages

---

_Артамонова Татьяна_  
_Нетология, 2025_
